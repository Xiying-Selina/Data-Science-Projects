# Data-Science-Projects
This repository records selected projects to showcase my skills including Python, R, SQL, and machine learning in data science. The cases contain predictive models, statistical analysis, workflow automation, and business intelligence dashboards. 

# Project List
1. **Yelp Data Analysis**: performed analysis on Yelp review to help start a new restaurant. keywords: **json, MySQL, SQL, Pandas, Numpy**.
   - We read five json files to pandas fataframe. These five datasets contains review, checkin, business, and tip. It is noticing that for review and tip files, we read them in chunks since it exceeds the limit of writing up one time. Then, we lunched a MySQL instance and created engine to load the data to sql.
   - We checked the connection of the database and created some tables to see if it works. After that, we made up 10 questions on the yelp data which would help to start a new restaurant and wrote 10 queries in sql to answer.
2. **KNIME**: created two KNIME workflows to solve two business problems. keywords: **KNIME, API, MongoDB**.
3. **ChatGPT Twitter Analysis**: implemented by the big data infrastructure using the selected technologies, such as programming language like **Python**, and big data frameworks like **Hadoop, Spark, and RDD**.
   - This project conducted a sentiment analysis to find trend topics and peopleâ€™s attitudes towards this innovative technology using a dataset from Twitter containing 500,000 tweets about ChatGPT from January to March 2023.
   - The data was preprocessed by changing the date format and removing unnecessary symbols and redundancies.
   - Several analysis tools were used on the data set, including Latent Dirichlet Analysis (LDA) and Exploratory Data Analysis (EDA) for uncovering hidden topics and understanding popular trends, unigram, bigram, and trigrams for most frequently used words, and Vader for sentiment analysis. 
4. **HR Prediction, Home Credit Default Risk, Housing Prediction, Retail Transactions**: predictive models using **Python**
   - **HR Prediction**: In this data analysis and modeling project, we first import essential packages like pandas, numpy, matplotlib, seaborn, and scikit-learn. Next, we read the dataset and explore variables related to the target variable "promoted," presenting visualizations like boxplots, histograms, bar charts, and scatter plots. We preprocess the data by handling missing values, duplicates, categorical columns, and skewed distributions. Then, we fit Logistic Regression, Tree-based model, and KNN models using scikit-learn, evaluating their performance with appropriate metrics. We justify our choice of performance metrics for each model. To streamline the process, we employ scikit-learn's Pipeline and Column Transformer for data preprocessing and model fitting. Finally, we report the best model's performance on test data, drawing conclusions about which model is optimal for predicting employee promotions.
   - **Home Credit Default Risk**: This project deals with a classification problem predicting how capable each applicant is at repaying a loan. Firstly we imported the 5 datasets(over 2G) and did exploratory data analysis including the inspection of the missing values and data visualizations such as heatmap, histograms, and scatter plots. Then we implemented feature engineering to create 5 new features based on the domain knowledge and merged all the tables. To preprocess the data, we dropped features with more than 5% missing values and defined pipelines for numerical and categorical columns, and used a column transformer to apply the preprocessing steps to specific columns. Next, we split the train test data and built three pipelines for decision tree, random forest, and xgboost models respectively. For performance, we defined the sensitivity, F1 score, and AUC as metrics for error analysis. To fine-tune the models, we refit the model with the best hyperparameters found in grid search on the entire training dataset, made predictions on the testing set and evaluated the model performance of the final model.
   - **Housing Prediction**: In this housing prediction project, we first conduct feature selection by loading the dataset and splitting it into train and test sets. We use correlation matrices and scatter plots to identify the top 5 most relevant features for predicting the target variable, creating a new dataset with only these features. In Task 2, we apply Linear Regression to the selected features, evaluating its performance on the test dataset using Mean Squared Error (MSE) and R-squared score, and visualize the model's performance. Task 3 involves applying L1 and L2 regularization to prevent overfitting and improve the model's performance. We train Ridge Regression with L2 regularization and Lasso Regression with L1 regularization, comparing their performance with the Linear Regression model. In Task 4, we use GridSearchCV to find the best lambda values for Ridge and Lasso Regression models, and then evaluate their performance on the test dataset using MSE and R-squared score. Ultimately, we compare the performance of all models to determine the most effective approach for housing price prediction.
   - **Retail Transactions**: In this retail transaction project, we first identify the primary key of the table. The target column is determined to be 'Quantity', and it appears to be a regression machine learning problem. We examine the distribution of the 'Quantity' column and evaluate its potential impact on the prediction goal, also checking for outliers. Next, we generate datetime features (day, month, year) from the 'Date' column. We analyze the correlation between price and quantity numerical features, comment on the correlation strength, and generate histograms for price to assess skewness and the presence of outliers. If skewed, we perform suitable transformations on these numeric variables and visualize their relationship with the target variable using bar charts, considering the presence of outliers. Additionally, we investigate the cardinality and rare values of at least two categorical features, discussing whether they are ordinal or nominal. For feature engineering, we create at least one text-based feature from the 'Product Name' column. NaN values are handled, and the approach is justified in the notebook. Finally, we develop an ML model to predict the quantity sold and report its performance on the test data.
5. **Health Insurance Lead Prediction**: predictive model using **R**
6. **Stock Valuation**: examining how stocks perform in diverse industries and using this analysis to devise an investment strategy using **SAS**.
7. **Supply Chain Analysis**: supply chain analysis using **R language**, inclusing **EDA, Regression, Time Series, ML models and linear programming**

# Other projects:
There are some projects in other format. The **Other.md** records them as links or screen shots.
- **NFT Dashboards**: Created two dashboards using advanced **sql** queries of two NFTs, Fidenza and Secret Skellies Society. 
- **Tableau Project**: Performed analysis on four streaming platforms, Netflix, Huluon, Disney and Amazon Prime using **Tableau**.
